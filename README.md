# ğŸ“˜ LangSmith â€“ Observability for LLM Applications (Part 1)

---

## 1ï¸âƒ£ Introduction: What is this about?

In this part, we learn about **LangSmith**, an important tool in **Generative AI (GenAI)**.

So far, our GenAI learning path looks like this:

* Started with **LangChain**
* Moved to **LangGraph** (agentic workflows)

While building LangGraph-based applications, we hit a very important requirement:

ğŸ‘‰ **Observability for LLM applications**

That is why we take a short detour and learn **LangSmith**.

---

## 2ï¸âƒ£ Why do we need LangSmith?

LangSmith is:

* A powerful **observability platform**
* Used to **debug**, **monitor**, and **evaluate** LLM applications
* Works seamlessly with **LangChain** and **LangGraph**

Before writing code, it is important to understand **why** such a tool is needed using real-world problems.

---

## 3ï¸âƒ£ Key Concept: Observability (VERY IMPORTANT)

### ğŸ”¹ What is Observability?

**Simple definition:**

Observability means understanding **what is happening inside a system** by analyzing:

* Logs
* Metrics
* Traces

In simple words:

ğŸ‘‰ Observability helps you understand **WHY something is happening**, even when the problem is unexpected.

---

## 4ï¸âƒ£ Why Observability is hard in LLM systems

LLM-based systems are:

âŒ **Non-deterministic**
Same input does not always give the same output

âŒ **Complex**
Multiple components like:

* LLM calls
* Agents
* Tools
* RAG pipelines
* Loops

âŒ **Black boxes**

* No proper error stack trace
* No traditional debugging

When things go wrong, we see:

* High latency
* High cost
* Hallucinations

ğŸ‘‰ Debugging becomes extremely difficult.

---

## 5ï¸âƒ£ Use Case 1: Latency Problem in LLM Workflow

### ğŸ§  Scenario

You build a **Job Application Assistant** for students:

Steps:

1. Read Job Description (JD)
2. Fetch resume from Google Drive
3. Match skills
4. Generate cover letter
5. Proofread

Normal behavior:

* â±ï¸ Takes ~2 minutes

Sudden issue:

* â±ï¸ Takes 7â€“10 minutes
* Users complain
* Revenue loss

### âŒ Problem

You only know:

* User input
* Final output
* Total time

You **do NOT know**:

* Which step is slow
* JD reading?
* Resume fetching?
* Matching?
* Generation?

ğŸ‘‰ No internal visibility
ğŸ‘‰ Debugging becomes guesswork

### âœ… How LangSmith helps

LangSmith shows:

* Step-by-step execution
* Time taken by each component
* Exact bottleneck

---

## 6ï¸âƒ£ Use Case 2: Cost Explosion in Agent-Based System

### ğŸ§  Scenario

You build a **Research Assistant Agent**:

Steps:

* Fetch papers (Google Scholar / arXiv)
* Read papers
* Extract key points
* Summarize report
* Allow chat on report

Cost behavior:

* Earlier: â‚¹0.50 per report
* Suddenly: â‚¹2 per report

### âŒ Problem

* Some reports are cheap
* Some are very expensive
* No errors
* No crashes

Agent mistake example:

> "Keep improving the report until it becomes perfect"

Agent behavior:

* Loops internally
* Repeats:

  * Fetch â†’ Read â†’ Summarize â†’ Evaluate â†’ Repeat

Result:

* ğŸ”¥ Token usage increases
* ğŸ’° Cost explodes
* ğŸ§© Hard to debug

### âœ… How LangSmith helps

LangSmith shows:

* How many times the agent looped
* Which steps repeated
* Token usage per step
* Cost per execution

---

## 7ï¸âƒ£ Use Case 3: Hallucinations in RAG System

### ğŸ§  Scenario

You build a **RAG-based chatbot** for a company (e.g., TCS):

Knowledge base:

* HR policies
* Leave policy
* Notice period
* Insurance

### âŒ Problem: Hallucination

Example wrong answer:

> "You can take leave anytime and go to Goa"

This causes:

* Misinformation
* Serious company issues

### â“ Why hallucinations happen in RAG

#### ğŸ”¹ 1. Retriever Issue

* Wrong documents fetched
* Irrelevant context

Example:

* Question: Notice period
* Retrieved doc: Company history

#### ğŸ”¹ 2. Generator (LLM) Issue

* Weak prompt
* Low-quality model
* Prompt does not enforce *"answer only from context"*

### âŒ Debugging problem

You cannot see:

* Which documents were retrieved
* Final prompt sent to LLM
* Whether retriever or generator failed

### âœ… How LangSmith helps

LangSmith shows:

* Retrieved documents
* Prompt sent to LLM
* LLM output
* Full step-by-step trace

---

## 8ï¸âƒ£ Common Problem in All Scenarios

All systems suffer from:

âŒ No internal visibility
âŒ Black-box behavior
âŒ Hard debugging

ğŸ‘‰ We need a tool that converts **Black Box â†’ White Box**

---

## 9ï¸âƒ£ What is LangSmith? (Formal Definition)

**LangSmith** is:

> A unified observability and evaluation platform that helps teams debug, test, and monitor LLM application performance.

### In simple words:

LangSmith records:

* Inputs
* Outputs
* Intermediate steps
* Latency
* Token usage
* Cost
* Errors
* Metadata

---

## ğŸ”Ÿ What does LangSmith Trace?

LangSmith tracks:

* âœ… User input & final output
* âœ… Intermediate steps (chains, agents, RAG)
* âœ… Latency (component-wise)
* âœ… Token usage (input + output)
* âœ… Cost estimation
* âœ… Errors
* âœ… Tags
* âœ… Metadata
* âœ… Optional user feedback

---

## 1ï¸âƒ£1ï¸âƒ£ Core Concepts in LangSmith

### ğŸ”¹ 1. Project

* Represents the entire LLM application
* Example: Chatbot, RAG app, Agent

### ğŸ”¹ 2. Trace

* One full execution of the application
* Example: One user query â†’ one response

### ğŸ”¹ 3. Run

* Execution of a single component
* Example:

  * Prompt
  * LLM call
  * Output parser

### ğŸ“Œ Hierarchy

```
Project
 â””â”€â”€ Trace (one execution)
      â””â”€â”€ Runs (each component)
```

---

## 1ï¸âƒ£2ï¸âƒ£ Setting Up LangSmith (Practical)

### ğŸ”¹ Step 1: Clone Repository

```bash
git clone <repo-url>
cd langsmith-masterclass
```

### ğŸ”¹ Step 2: Create Virtual Environment

```bash
python -m venv myenv
```

Activate:

```bash
myenv\Scripts\activate   # Windows
```

### ğŸ”¹ Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

### ğŸ”¹ Step 4: Create LangSmith Account

* Visit LangSmith website
* Sign up / Login
* Generate **Personal Access Token**

### ğŸ”¹ Step 5: Create `.env` file

```env
OPENAI_API_KEY=your_openai_key

LANGCHAIN_TRACING_V2=true
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
LANGCHAIN_API_KEY=your_langsmith_key
LANGCHAIN_PROJECT=langsmith-demo
```

---

## 1ï¸âƒ£3ï¸âƒ£ First LangSmith Trace (Simple LLM App)

### ğŸ”¹ LangChain Code

```python
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.output_parsers import StrOutputParser

prompt = PromptTemplate.from_template("Answer: {question}")
model = ChatOpenAI()
parser = StrOutputParser()

chain = prompt | model | parser

print(chain.invoke({"question": "What is the capital of Peru?"}))
```

### ğŸ”¹ Important Point

â— No LangSmith-specific code is written.

LangSmith automatically traces because:

* Environment variables are enabled

### ğŸ”¹ What you see in LangSmith UI

* Project: `langsmith-demo`
* One Trace per execution
* Runs:

  * PromptTemplate
  * ChatOpenAI
  * OutputParser

You can inspect:

* Inputs / Outputs
* Latency
* Tokens
* Cost

---

## 1ï¸âƒ£4ï¸âƒ£ Setting Project Name from Code

```python
import os
os.environ["LANGCHAIN_PROJECT"] = "sequential-llm-app"
```

This overrides the project name from `.env`.

---

## 1ï¸âƒ£5ï¸âƒ£ Adding Tags & Metadata

```python
config = {
    "tags": ["llm-app", "report-generation", "summarization"],
    "metadata": {
        "model": "gpt-4o-mini",
        "temperature": 0.7,
        "parser": "StrOutputParser"
    },
    "run_name": "Sequential Chain"
}

chain.invoke({"topic": "Unemployment in India"}, config=config)
```

---

## 1ï¸âƒ£6ï¸âƒ£ What We Learned in Part 1

âœ… Why observability is critical for LLM apps
âœ… Latency, cost & hallucination problems
âœ… What LangSmith is and why it exists
âœ… Core concepts: Project, Trace, Run
âœ… Automatic tracing in LangChain apps
âœ… How to add:

* Project names
* Tags
* Metadata

---

ğŸ“Œ **Next Part:** LangSmith evaluations, debugging strategies, and real-world workflows

# ğŸ“˜ LangSmith â€“ Tracing RAG, Agents & LangGraph

*(Part 2 â€“ Simple English Notes with Code)*

---

## 1ï¸âƒ£ Why LangSmith + RAG is a Very Good Idea

### ğŸ”¹ What is a RAG application?

**RAG = Retrieval Augmented Generation**

In a RAG app:

1. User asks a question
2. Retriever fetches relevant documents
3. LLM receives:

   * The question
   * Retrieved context
4. LLM combines both and generates the final answer

ğŸ‘‰ Used for:

* PDFs
* Company documents
* Personal data
* Knowledge bases

---

## 2ï¸âƒ£ The Real Problem with RAG in Production

Even though RAG sounds simple, many production systems fail.

### âŒ Two common error types

#### ğŸ”´ Error Type 1: Retriever Error

* Retriever fetches wrong / irrelevant chunks
* LLM receives bad context
* Final answer becomes incorrect

#### ğŸ”´ Error Type 2: Generator (LLM) Error

* Retriever fetches correct chunks
* LLM hallucinates or ignores context
* Final answer is still wrong

### âŒ The BIG Production Problem

You only see:

* User question
* Final answer

You **cannot see**:

* What documents were retrieved
* What exact prompt was sent to the LLM

ğŸ‘‰ No intermediate visibility

---

## 3ï¸âƒ£ How LangSmith Solves This Problem

LangSmith traces **every intermediate step**:

It records:

* User question
* Retrieved documents
* Final prompt (question + context)
* LLM response

ğŸ‘‰ Now you can clearly identify:

* Retriever failure âŒ
* Generator failure âŒ

---

## 4ï¸âƒ£ Simple RAG App Used in Demo

### ğŸ“„ Data

* PDF: *Introduction to Statistical Learning*
* Stored locally inside project folder

### ğŸ§  Example Queries

* "Who is the author of this book?"
* "Summarize chapter 6"

---

## 5ï¸âƒ£ RAG Application Flow (Very Important)

### ğŸ” Step-by-step Flow

1. Load PDF
2. Split PDF into chunks
3. Generate embeddings
4. Create retriever
5. Pass:

   * Question
   * Retrieved context
6. LLM generates final answer

---

## 6ï¸âƒ£ Core RAG Code Structure (Simplified)

### ğŸ”¹ Load PDF

```python
from langchain.document_loaders import PyPDFLoader

loader = PyPDFLoader("book.pdf")
documents = loader.load()
```

### ğŸ”¹ Split Documents

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=150
)

chunks = splitter.split_documents(documents)
```

### ğŸ”¹ Create Embeddings & Retriever

```python
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS

embeddings = OpenAIEmbeddings()
vectorstore = FAISS.from_documents(chunks, embeddings)

retriever = vectorstore.as_retriever()
```

### ğŸ”¹ Prompt Template (VERY IMPORTANT)

```python
from langchain.prompts import ChatPromptTemplate

prompt = ChatPromptTemplate.from_template(
    """
    Answer ONLY from the provided context.
    If answer not found, say "I don't know".

    Question: {question}
    Context: {context}
    """
)
```

---

## 7ï¸âƒ£ RAG Chain Structure (Conceptual)

**Parallel Chain**

* Path 1 â†’ Question (unchanged)
* Path 2 â†’ Question â†’ Retriever â†’ Context

Outputs:

* Question
* Context

Then:

Prompt â†’ LLM â†’ Output Parser

---

## 8ï¸âƒ£ Setting LangSmith Project Name

```python
import os
os.environ["LANGCHAIN_PROJECT"] = "rag-chatbot"
```

---

## 9ï¸âƒ£ What LangSmith Shows in UI

LangSmith beautifully visualizes:

* Entire RAG chain
* RunnableParallel
* Retriever calls
* Prompt template
* LLM calls
* Token usage
* Latency per step
* Cost

---

## ğŸ”Ÿ Problem #1: Partial Tracing âŒ

### âŒ Issue

LangSmith was tracing only:

* Chain execution

It was **NOT tracing**:

* PDF loading
* Chunking
* Embeddings

ğŸ‘‰ Because LangSmith auto-traces only **LangChain Runnables**

---

## 1ï¸âƒ£1ï¸âƒ£ Solution: `@traceable` Decorator

### ğŸ”¹ Import

```python
from langsmith import traceable
```

### ğŸ”¹ Convert Steps into Traceable Functions

```python
@traceable(name="Load PDF")
def load_pdf(path):
    loader = PyPDFLoader(path)
    return loader.load()

@traceable(name="Split Documents")
def split_documents(docs):
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=150
    )
    return splitter.split_documents(docs)

@traceable(name="Build Vector Store")
def build_vectorstore(chunks):
    embeddings = OpenAIEmbeddings()
    vectorstore = FAISS.from_documents(chunks, embeddings)
    return vectorstore.as_retriever()
```

### ğŸ”¹ Pipeline Function

```python
@traceable(name="Setup Pipeline")
def setup_pipeline(pdf_path):
    docs = load_pdf(pdf_path)
    chunks = split_documents(docs)
    retriever = build_vectorstore(chunks)
    return retriever
```

---

## 1ï¸âƒ£2ï¸âƒ£ Result in LangSmith UI

Now LangSmith shows:

* Setup Pipeline (trace)
* Load PDF
* Split Documents
* Build Vector Store
* RAG Query (trace)

Each step displays:

* Inputs
* Outputs
* Time taken
* Metadata

---

## 1ï¸âƒ£3ï¸âƒ£ Adding Tags & Metadata (Advanced)

```python
@traceable(
    name="Build Vector Store",
    tags=["embedding", "vectorstore"],
    metadata={
        "embedding_model": "text-embedding-3-small",
        "dimensions": 1536
    }
)
def build_vectorstore(chunks):
    ...
```

ğŸ‘‰ Helps in:

* Searching traces
* Debugging large systems
* Monitoring specific components

---

## 1ï¸âƒ£4ï¸âƒ£ Problem #2: High Latency âŒ

### âŒ Issue

Every query:

* Reloads PDF
* Re-chunks
* Re-embeds

â¡ï¸ Extremely slow (200+ seconds)

---

## 1ï¸âƒ£5ï¸âƒ£ Solution: Persistent Vector Store (FAISS)

### ğŸ”¹ Concept

* First run â†’ Build index
* Save index to disk
* Next runs â†’ Load index

### ğŸ”¹ Logic (Conceptual)

```python
if index_exists():
    load_index()
else:
    build_index()
    save_index()
```

### ğŸ”¹ Performance Benefit

| Scenario  | Time     |
| --------- | -------- |
| First run | ~30 sec  |
| Next runs | ~1â€“4 sec |

---

## 1ï¸âƒ£6ï¸âƒ£ When Is Index Rebuilt?

Index rebuild happens when:

* PDF content changes
* PDF metadata changes
* Chunk size / overlap changes
* Embedding model changes

---

## 1ï¸âƒ£7ï¸âƒ£ Key Production Lesson (VERY IMPORTANT)

ğŸ‘‰ **Never rebuild embeddings on every query**

Always:

* Pre-build vector index
* Reuse embeddings

---

# ğŸ§  Agent Tracing with LangSmith

## 1ï¸âƒ£ Why Agent Tracing Matters

Agents are:

* Autonomous
* Multi-step
* Tool-using
* Non-deterministic

ğŸ‘‰ Debugging agents **without tracing is impossible**

---

## 2ï¸âƒ£ Agent Example Used

Tools:

* DuckDuckGo Search
* Weather API

Agent loop:

**Thought â†’ Action â†’ Observation â†’ Repeat**

---

## 3ï¸âƒ£ What LangSmith Shows for Agents

LangSmith traces:

* Scratchpad
* Prompt
* Tool calls
* Tool outputs
* Updated scratchpad
* Final answer

---

## 4ï¸âƒ£ Example Agent Flow

**Query:**

> What is the current temperature of Gurgaon?

**Steps:**

1. Thought: I should use weather tool
2. Action: Call weather API
3. Observation: Weather data
4. Thought: I now know the answer
5. Final answer

ğŸ‘‰ Every step is visible in LangSmith

---

## 5ï¸âƒ£ Multi-tool Agent Example

**Query:**

> Find birth place of Kalpana Chawla and give its temperature

Agent uses:

* Search tool â†’ Birthplace
* Weather tool â†’ Temperature

LangSmith shows:

* Tool selection
* Inputs & outputs
* Reasoning chain

---

## 6ï¸âƒ£ Why This Is HUGE

You can:

* Debug hallucinations
* Track cost
* Track tokens
* Understand agent reasoning
* Improve prompts

---

# ğŸ”— LangGraph + LangSmith Integration

## 1ï¸âƒ£ LangGraph Basics (Quick Recap)

* LLM apps as workflows
* Nodes = tasks
* Edges = execution flow

Supports:

* Parallel execution
* Conditional branches
* Loops

---

## 2ï¸âƒ£ LangSmith Integration Concept

### ğŸ”¹ Two Golden Rules

1ï¸âƒ£ Entire graph execution = **One Trace**
2ï¸âƒ£ Each node execution = **One Run**

---

## 3ï¸âƒ£ Example: Essay Evaluation Graph

**Input:**

* Essay text

**Nodes:**

* Language evaluation
* Analysis evaluation
* Clarity evaluation

**Final Node:**

* Overall feedback
* Average score

---

## 4ï¸âƒ£ What LangSmith Shows

* Parallel node execution
* Node-wise latency
* Node-wise cost
* Inputs & outputs
* Structured outputs

---

## 5ï¸âƒ£ Structured LLM Outputs (Important)

```python
llm = ChatOpenAI().with_structured_output(EvaluationSchema)
```

Ensures:

* Fixed schema
* Reliable outputs
* Easy debugging

---

## 6ï¸âƒ£ Why LangSmith is PERFECT for LangGraph

Because:

* Graphs are complex
* Branching is hard to debug
* LangSmith visualizes everything

---

# ğŸŒŸ Other Important Features of LangSmith

## 1ï¸âƒ£ Monitoring & Alerting

### ğŸ”¹ Monitoring

Analyze multiple traces together to track:

* Latency
* Cost
* Token usage
* Error rate

### ğŸ”¹ Alerts

Examples:

* Latency > 5s â†’ alert team
* Cost spike â†’ notify team

ğŸ‘‰ Prevents silent production failures

---

## 2ï¸âƒ£ Evaluation (LLMOps)

Used to:

* Compare model versions
* Compare prompts
* Prevent regressions

Supports:

* LLM-as-a-judge
* Faithfulness
* Relevance
* Custom Python evaluators

---

## 3ï¸âƒ£ Prompt Experimentation (A/B Testing)

* Compare Prompt A vs Prompt B
* Same dataset
* Same metrics
* Stored history

ğŸ‘‰ Scientific prompt engineering

---

## 4ï¸âƒ£ Dataset Creation & Annotation

* Create datasets from traces
* Add annotations
* Reuse datasets across projects

---

## 5ï¸âƒ£ User Feedback Integration

* Thumbs up / down
* Structured feedback
* Linked to traces

Helps:

* Improve real-world quality
* Understand user sentiment

---

## 6ï¸âƒ£ Collaboration

* Share trace links
* Team debugging
* Shared dashboards
* Prompt versioning

---

# ğŸ”š Final Summary

LangSmith is **NOT just observability**.

It is a complete **LLM Ops platform**:

âœ… Observability
âœ… Debugging
âœ… Monitoring & Alerts
âœ… Evaluation
âœ… Prompt experimentation
âœ… Dataset creation
âœ… User feedback
âœ… Collaboration

