# ğŸ“˜ LangSmith â€“ Observability for LLM Applications (Part 1)

---

## 1ï¸âƒ£ Introduction: What is this about?

In this part, we learn about **LangSmith**, an important tool in **Generative AI (GenAI)**.

So far, our GenAI learning path looks like this:

* Started with **LangChain**
* Moved to **LangGraph** (agentic workflows)

While building LangGraph-based applications, we hit a very important requirement:

ğŸ‘‰ **Observability for LLM applications**

That is why we take a short detour and learn **LangSmith**.

---

## 2ï¸âƒ£ Why do we need LangSmith?

LangSmith is:

* A powerful **observability platform**
* Used to **debug**, **monitor**, and **evaluate** LLM applications
* Works seamlessly with **LangChain** and **LangGraph**

Before writing code, it is important to understand **why** such a tool is needed using real-world problems.

---

## 3ï¸âƒ£ Key Concept: Observability (VERY IMPORTANT)

### ğŸ”¹ What is Observability?

**Simple definition:**

Observability means understanding **what is happening inside a system** by analyzing:

* Logs
* Metrics
* Traces

In simple words:

ğŸ‘‰ Observability helps you understand **WHY something is happening**, even when the problem is unexpected.

---

## 4ï¸âƒ£ Why Observability is hard in LLM systems

LLM-based systems are:

âŒ **Non-deterministic**
Same input does not always give the same output

âŒ **Complex**
Multiple components like:

* LLM calls
* Agents
* Tools
* RAG pipelines
* Loops

âŒ **Black boxes**

* No proper error stack trace
* No traditional debugging

When things go wrong, we see:

* High latency
* High cost
* Hallucinations

ğŸ‘‰ Debugging becomes extremely difficult.

---

## 5ï¸âƒ£ Use Case 1: Latency Problem in LLM Workflow

### ğŸ§  Scenario

You build a **Job Application Assistant** for students:

Steps:

1. Read Job Description (JD)
2. Fetch resume from Google Drive
3. Match skills
4. Generate cover letter
5. Proofread

Normal behavior:

* â±ï¸ Takes ~2 minutes

Sudden issue:

* â±ï¸ Takes 7â€“10 minutes
* Users complain
* Revenue loss

### âŒ Problem

You only know:

* User input
* Final output
* Total time

You **do NOT know**:

* Which step is slow
* JD reading?
* Resume fetching?
* Matching?
* Generation?

ğŸ‘‰ No internal visibility
ğŸ‘‰ Debugging becomes guesswork

### âœ… How LangSmith helps

LangSmith shows:

* Step-by-step execution
* Time taken by each component
* Exact bottleneck

---

## 6ï¸âƒ£ Use Case 2: Cost Explosion in Agent-Based System

### ğŸ§  Scenario

You build a **Research Assistant Agent**:

Steps:

* Fetch papers (Google Scholar / arXiv)
* Read papers
* Extract key points
* Summarize report
* Allow chat on report

Cost behavior:

* Earlier: â‚¹0.50 per report
* Suddenly: â‚¹2 per report

### âŒ Problem

* Some reports are cheap
* Some are very expensive
* No errors
* No crashes

Agent mistake example:

> "Keep improving the report until it becomes perfect"

Agent behavior:

* Loops internally
* Repeats:

  * Fetch â†’ Read â†’ Summarize â†’ Evaluate â†’ Repeat

Result:

* ğŸ”¥ Token usage increases
* ğŸ’° Cost explodes
* ğŸ§© Hard to debug

### âœ… How LangSmith helps

LangSmith shows:

* How many times the agent looped
* Which steps repeated
* Token usage per step
* Cost per execution

---

## 7ï¸âƒ£ Use Case 3: Hallucinations in RAG System

### ğŸ§  Scenario

You build a **RAG-based chatbot** for a company (e.g., TCS):

Knowledge base:

* HR policies
* Leave policy
* Notice period
* Insurance

### âŒ Problem: Hallucination

Example wrong answer:

> "You can take leave anytime and go to Goa"

This causes:

* Misinformation
* Serious company issues

### â“ Why hallucinations happen in RAG

#### ğŸ”¹ 1. Retriever Issue

* Wrong documents fetched
* Irrelevant context

Example:

* Question: Notice period
* Retrieved doc: Company history

#### ğŸ”¹ 2. Generator (LLM) Issue

* Weak prompt
* Low-quality model
* Prompt does not enforce *"answer only from context"*

### âŒ Debugging problem

You cannot see:

* Which documents were retrieved
* Final prompt sent to LLM
* Whether retriever or generator failed

### âœ… How LangSmith helps

LangSmith shows:

* Retrieved documents
* Prompt sent to LLM
* LLM output
* Full step-by-step trace

---

## 8ï¸âƒ£ Common Problem in All Scenarios

All systems suffer from:

âŒ No internal visibility
âŒ Black-box behavior
âŒ Hard debugging

ğŸ‘‰ We need a tool that converts **Black Box â†’ White Box**

---

## 9ï¸âƒ£ What is LangSmith? (Formal Definition)

**LangSmith** is:

> A unified observability and evaluation platform that helps teams debug, test, and monitor LLM application performance.

### In simple words:

LangSmith records:

* Inputs
* Outputs
* Intermediate steps
* Latency
* Token usage
* Cost
* Errors
* Metadata

---

## ğŸ”Ÿ What does LangSmith Trace?

LangSmith tracks:

* âœ… User input & final output
* âœ… Intermediate steps (chains, agents, RAG)
* âœ… Latency (component-wise)
* âœ… Token usage (input + output)
* âœ… Cost estimation
* âœ… Errors
* âœ… Tags
* âœ… Metadata
* âœ… Optional user feedback

---

## 1ï¸âƒ£1ï¸âƒ£ Core Concepts in LangSmith

### ğŸ”¹ 1. Project

* Represents the entire LLM application
* Example: Chatbot, RAG app, Agent

### ğŸ”¹ 2. Trace

* One full execution of the application
* Example: One user query â†’ one response

### ğŸ”¹ 3. Run

* Execution of a single component
* Example:

  * Prompt
  * LLM call
  * Output parser

### ğŸ“Œ Hierarchy

```
Project
 â””â”€â”€ Trace (one execution)
      â””â”€â”€ Runs (each component)
```

---

## 1ï¸âƒ£2ï¸âƒ£ Setting Up LangSmith (Practical)

### ğŸ”¹ Step 1: Clone Repository

```bash
git clone <repo-url>
cd langsmith-masterclass
```

### ğŸ”¹ Step 2: Create Virtual Environment

```bash
python -m venv myenv
```

Activate:

```bash
myenv\Scripts\activate   # Windows
```

### ğŸ”¹ Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

### ğŸ”¹ Step 4: Create LangSmith Account

* Visit LangSmith website
* Sign up / Login
* Generate **Personal Access Token**

### ğŸ”¹ Step 5: Create `.env` file

```env
OPENAI_API_KEY=your_openai_key

LANGCHAIN_TRACING_V2=true
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
LANGCHAIN_API_KEY=your_langsmith_key
LANGCHAIN_PROJECT=langsmith-demo
```

---

## 1ï¸âƒ£3ï¸âƒ£ First LangSmith Trace (Simple LLM App)

### ğŸ”¹ LangChain Code

```python
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.output_parsers import StrOutputParser

prompt = PromptTemplate.from_template("Answer: {question}")
model = ChatOpenAI()
parser = StrOutputParser()

chain = prompt | model | parser

print(chain.invoke({"question": "What is the capital of Peru?"}))
```

### ğŸ”¹ Important Point

â— No LangSmith-specific code is written.

LangSmith automatically traces because:

* Environment variables are enabled

### ğŸ”¹ What you see in LangSmith UI

* Project: `langsmith-demo`
* One Trace per execution
* Runs:

  * PromptTemplate
  * ChatOpenAI
  * OutputParser

You can inspect:

* Inputs / Outputs
* Latency
* Tokens
* Cost

---

## 1ï¸âƒ£4ï¸âƒ£ Setting Project Name from Code

```python
import os
os.environ["LANGCHAIN_PROJECT"] = "sequential-llm-app"
```

This overrides the project name from `.env`.

---

## 1ï¸âƒ£5ï¸âƒ£ Adding Tags & Metadata

```python
config = {
    "tags": ["llm-app", "report-generation", "summarization"],
    "metadata": {
        "model": "gpt-4o-mini",
        "temperature": 0.7,
        "parser": "StrOutputParser"
    },
    "run_name": "Sequential Chain"
}

chain.invoke({"topic": "Unemployment in India"}, config=config)
```

---

## 1ï¸âƒ£6ï¸âƒ£ What We Learned in Part 1

âœ… Why observability is critical for LLM apps
âœ… Latency, cost & hallucination problems
âœ… What LangSmith is and why it exists
âœ… Core concepts: Project, Trace, Run
âœ… Automatic tracing in LangChain apps
âœ… How to add:

* Project names
* Tags
* Metadata

---

ğŸ“Œ **Next Part:** LangSmith evaluations, debugging strategies, and real-world workflows
